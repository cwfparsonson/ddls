{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def42816-abf3-48c7-9e9d-11daa38fb7cf",
   "metadata": {},
   "source": [
    "# NOTE\n",
    "\n",
    "Think RLLib does not store per-step/episode/epoch stats, but rather stores the rolling mean/min/max per-step/episode/epoch stats. Seen somewhere online that this is done with a history window of size 100 https://discuss.ray.io/t/custom-metrics-only-mean-value/636/3. Don't think there's a way to change this, and also means plots may look different from what you'd expect..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d67d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "from ddls.plotting.plotting import plot_line, plot_bar, plot_hist\n",
    "\n",
    "from collections import defaultdict\n",
    "from sqlitedict import SqliteDict\n",
    "import pprint\n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d2363a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files\n",
    "base_folder = '/scratch/datasets/ddls/sims/'\n",
    "\n",
    "# base_name = 'job_placing'\n",
    "# # ids = [108]\n",
    "# ids = [108, 116]\n",
    "\n",
    "# base_name = 'ramp_job_placement_shaping'\n",
    "# ids = [3]\n",
    "# ids = [27]\n",
    "# ids = [44]\n",
    "# ids = [73]\n",
    "# ids = [133]\n",
    "# ids = [176]\n",
    "\n",
    "# ids = [289]\n",
    "# ids = [289, 322]\n",
    "# ids = [322]\n",
    "\n",
    "\n",
    "\n",
    "base_name = 'ramp_job_partitioning'\n",
    "# ids = [104]\n",
    "ids = [442, 446]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31408f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "i: 442 | agent: ramp_job_partitioning_442 | paths: ['/scratch/datasets/ddls/sims/ramp_job_partitioning/ramp_job_partitioning_442/rllib_results.sqlite', '/scratch/datasets/ddls/sims/ramp_job_partitioning/ramp_job_partitioning_442/launcher_stats.sqlite']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'ray._private' has no attribute 'worker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6c74e791f588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSqliteDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/zciccwf/py36/envs/ddls/lib/python3.9/site-packages/sqlitedict.py\u001b[0m in \u001b[0;36miteritems\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mGET_ITEMS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'SELECT key, value FROM \"%s\" ORDER BY rowid'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtablename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGET_ITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/zciccwf/py36/envs/ddls/lib/python3.9/site-packages/sqlitedict.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;34m\"\"\"Deserialize objects retrieved from SQLite.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/zciccwf/py36/envs/ddls/lib/python3.9/site-packages/ray/rllib/algorithms/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAlgorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAlgorithmConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m __all__ = [\n",
      "\u001b[0;32m/scratch/zciccwf/py36/envs/ddls/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_private\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musage_lib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTagKey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_extra_usage_tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mActorHandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGetTimeoutError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRayActorError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRayError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/zciccwf/py36/envs/ddls/lib/python3.9/site-packages/ray/_private/usage/usage_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_private\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_init_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mput_pre_init_usage_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'ray._private' has no attribute 'worker'"
     ]
    }
   ],
   "source": [
    "results = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "for i in ids:\n",
    "    agent = base_name + f'_{i}'\n",
    "    paths = [reset_folder for reset_folder in glob.glob(base_folder + f'{base_name}/{agent}/*.sqlite')]\n",
    "    print(f'\\ni: {i} | agent: {agent} | paths: {paths}')\n",
    "    \n",
    "    for path in paths:\n",
    "        start_time = time.time()\n",
    "        file = path.split('/')[-1].split('.')[0]\n",
    "        with SqliteDict(path) as log:\n",
    "            for key, val in log.items():\n",
    "                results[file][agent][key].extend(val)\n",
    "            log.close()\n",
    "        print(f'Loaded {path} in {time.time() - start_time:.3f} s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92336dee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(results.keys())\n",
    "print('')\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac4706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLLIB EPOCH ACTOR STATS\n",
    "metrics_to_plot = {\n",
    "                   'episode_reward_mean', \n",
    "                   'episode_reward_max', \n",
    "                   'episode_reward_min', \n",
    "                   'normalised_episode_reward_mean',\n",
    "                  }\n",
    "epochs_stats = defaultdict(lambda: [])\n",
    "if 'rllib_results' in results:\n",
    "    for agent, training_stats in results['rllib_results'].items():\n",
    "        # print(training_stats)\n",
    "        epochs_stats['Epoch'].extend(training_stats['training_iteration'])\n",
    "        epochs_stats['Agent'].extend([agent for _ in range(len(training_stats['training_iteration']))])\n",
    "        for metric in metrics_to_plot:\n",
    "            if metric not in {'normalised_episode_reward_mean'}:\n",
    "                epochs_stats[metric].extend(training_stats[metric])\n",
    "        \n",
    "        if 'normalised_episode_reward_mean' in metrics_to_plot:\n",
    "            max_reward = np.amax(training_stats['episode_reward_max'])\n",
    "            min_reward = np.amin(training_stats['episode_reward_min'])\n",
    "            epochs_stats['normalised_episode_reward_mean'].extend([(abs(mean_reward - min_reward) / (abs(max_reward - min_reward))) for mean_reward in training_stats['episode_reward_mean']])\n",
    "            \n",
    "epochs_stats_df = pd.DataFrame(epochs_stats)\n",
    "display(epochs_stats_df)\n",
    "\n",
    "scaling_factor = 1\n",
    "x = 'Epoch'\n",
    "hue = 'Agent'\n",
    "for metric in metrics_to_plot:\n",
    "    print(f'Plotting {metric} vs. {x}...')\n",
    "    start_time = time.time()\n",
    "    fig = plot_line(epochs_stats_df, \n",
    "                    x=x, \n",
    "                    y=metric, \n",
    "                    hue=hue, \n",
    "                    xlabel=x, \n",
    "                    ylabel=metric, \n",
    "                    err_style='band', # 'band' 'bars'\n",
    "                    ci=68, # 95 68\n",
    "                    scaling_factor=scaling_factor,\n",
    "                    show_fig=False)\n",
    "    print(f'Plotted {metric} vs. {x} in {time.time() - start_time:.3f} s.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf35cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RLLIB EPOCH ACTOR STATS WITH PER-STEP RESOLUTION\n",
    "# metrics_to_plot = {'episode_reward', 'episode_lengths'}\n",
    "# epochs_hist_stats = defaultdict(lambda: [])\n",
    "# if 'rllib_results' in results:\n",
    "#     for agent in results['rllib_results'].keys():\n",
    "#         hist_stats = results['rllib_results'][agent]['hist_stats']\n",
    "#         print(hist_stats)\n",
    "#         for idx, epoch_hist_stats in enumerate(hist_stats):\n",
    "#             for metric in metrics_to_plot:\n",
    "#                 if metric not in {'normalised_episode_reward'}:\n",
    "#                     for step_metric in epoch_hist_stats[metric]:\n",
    "#                         epochs_hist_stats[metric].append(step_metric)\n",
    "#             epochs_hist_stats['Agent'].extend([agent for _ in range(len(epoch_hist_stats[metric]))])\n",
    "#             epochs_hist_stats['Epoch'].extend([results['rllib_results'][agent]['training_iteration'][idx] for _ in range(len(epoch_hist_stats[metric]))])\n",
    "            \n",
    "            \n",
    "# epochs_hist_stats_df = pd.DataFrame(epochs_hist_stats)\n",
    "# display(epochs_hist_stats_df)\n",
    "\n",
    "# scaling_factor = 1\n",
    "# x = 'Epoch'\n",
    "# hue = 'Agent'\n",
    "# for metric in metrics_to_plot:\n",
    "#     print(f'Plotting {metric} vs. {x}...')\n",
    "#     start_time = time.time()\n",
    "#     fig = plot_line(epochs_hist_stats_df, \n",
    "#                     x=x, \n",
    "#                     y=metric, \n",
    "#                     hue=hue, \n",
    "#                     xlabel=x, \n",
    "#                     ylabel=metric, \n",
    "#                     err_style='band', # 'band' 'bars'\n",
    "#                     ci=68, # 95 68\n",
    "#                     scaling_factor=scaling_factor,\n",
    "#                     show_fig=False)\n",
    "#     print(f'Plotted {metric} vs. {x} in {time.time() - start_time:.3f} s.')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93579b6b-44ab-47fd-9e64-e9f5d39bb6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLLIB CUSTOM METRICS EPOCH ACTOR STATS\n",
    "metrics_to_plot = {\n",
    "                   'mean_num_mounted_workers_mean', \n",
    "                   'mean_num_mounted_channels_mean',\n",
    "    \n",
    "                   'mean_compute_throughput_mean',\n",
    "                   'mean_comm_throughput_mean',\n",
    "                   'mean_cluster_throughput_mean',\n",
    "    \n",
    "                   'mean_compute_overhead_frac_mean',\n",
    "                   'mean_comm_overhead_frac_mean',\n",
    "    \n",
    "                   'job_completion_time_mean',\n",
    "                   'job_communication_overhead_time_mean', \n",
    "                   'job_computation_overhead_time_mean',\n",
    "                  }\n",
    "epochs_stats = defaultdict(lambda: [])\n",
    "if 'rllib_results' in results:\n",
    "    for agent, training_stats in results['rllib_results'].items():\n",
    "        # print(training_stats['custom_metrics'])\n",
    "        for idx, epoch_hist_stats in enumerate(training_stats['custom_metrics']):\n",
    "            # epochs_stats['Epoch'].extend(training_stats['training_iteration'])\n",
    "            # epochs_stats['Agent'].extend([agent for _ in range(len(training_stats['training_iteration']))])\n",
    "            # print(epoch_hist_stats)\n",
    "            for metric in metrics_to_plot:\n",
    "                if metric not in {'normalised_episode_reward_mean'}:\n",
    "                    if metric in epoch_hist_stats:\n",
    "                        epochs_stats[metric].append(epoch_hist_stats[metric])\n",
    "                    else:\n",
    "                        epochs_stats[metric].append(np.nan)\n",
    "            epochs_stats['Agent'].append(agent)\n",
    "            epochs_stats['Epoch'].append(idx)\n",
    "                \n",
    "epochs_stats_df = pd.DataFrame(epochs_stats)\n",
    "display(epochs_stats_df)\n",
    "\n",
    "scaling_factor = 1\n",
    "x = 'Epoch'\n",
    "hue = 'Agent'\n",
    "for metric in metrics_to_plot:\n",
    "    print(f'Plotting {metric} vs. {x}...')\n",
    "    start_time = time.time()\n",
    "    fig = plot_line(epochs_stats_df, \n",
    "                    x=x, \n",
    "                    y=metric, \n",
    "                    hue=hue, \n",
    "                    xlabel=x, \n",
    "                    ylabel=metric, \n",
    "                    err_style='band', # 'band' 'bars'\n",
    "                    ci=68, # 95 68\n",
    "                    scaling_factor=scaling_factor,\n",
    "                    show_fig=False)\n",
    "    print(f'Plotted {metric} vs. {x} in {time.time() - start_time:.3f} s.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b76ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLLIB EPOCH LEARNER STATS\n",
    "metrics_to_plot = set()\n",
    "epochs_learner_stats = defaultdict(lambda: [])\n",
    "if 'rllib_results' in results:\n",
    "    for agent, training_stats in results['rllib_results'].items():\n",
    "        epochs_stats['Epoch'].extend(training_stats['training_iteration'])\n",
    "        epochs_stats['Agent'].extend([agent for _ in range(len(training_stats['training_iteration']))])\n",
    "        \n",
    "        info = results['rllib_results'][agent]['info']\n",
    "        for idx, epoch_info in enumerate(info):\n",
    "            for metric, stat in epoch_info['learner']['default_policy']['learner_stats'].items():\n",
    "                metrics_to_plot.add(metric)\n",
    "                epochs_learner_stats[metric].append(stat)\n",
    "            epochs_learner_stats['Agent'].append(agent)\n",
    "            epochs_learner_stats['Epoch'].append(results['rllib_results'][agent]['training_iteration'][idx])\n",
    "\n",
    "            \n",
    "epochs_learner_stats_df = pd.DataFrame(epochs_learner_stats)\n",
    "display(epochs_learner_stats_df)\n",
    "\n",
    "scaling_factor = 1\n",
    "x = 'Epoch'\n",
    "hue = 'Agent'\n",
    "for metric in metrics_to_plot:\n",
    "    print(f'Plotting {metric} vs. {x}...')\n",
    "    start_time = time.time()\n",
    "    fig = plot_line(epochs_learner_stats_df, \n",
    "                    x=x, \n",
    "                    y=metric, \n",
    "                    hue=hue, \n",
    "                    xlabel=x, \n",
    "                    ylabel=metric, \n",
    "                    err_style='band', # 'band' 'bars'\n",
    "                    ci=68, # 95 68\n",
    "                    scaling_factor=scaling_factor,\n",
    "                    show_fig=False)\n",
    "    print(f'Plotted {metric} vs. {x} in {time.time() - start_time:.3f} s.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb3b2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17684dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd0872b-b878-4c6e-9ac2-5a8bd4a63891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f4b81c-2a2a-4fae-bbf8-0265ecd056c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddls",
   "language": "python",
   "name": "ddls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
