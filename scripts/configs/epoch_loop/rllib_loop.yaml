_target_: ddls.loops.rllib_epoch_loop.RLlibEpochLoop

# define string path to the model you want to use
path_to_model_cls: ddls.ml_models.policies.GNNPolicy

# define string path to the environment you want to use
#path_to_env_cls: ddls.environments.job_placing.job_placing_all_nodes_environment.JobPlacingAllNodesEnvironment
path_to_env_cls: ddls.environments.ramp_job_placement_shaping.ramp_job_placement_shaping_environment.RampJobPlacementShapingEnvironment

# define string path to the rllib trainer you want to use
path_to_rllib_trainer_cls: ray.rllib.agents.ppo.PPOTrainer

# define validator/evaluation loop (will use same setup as rllib_config below but with following overrides)
path_to_validator_cls: ddls.loops.rllib_eval_loop.RLlibEvalLoop
test_time_checkpoint_path: /scratch/datasets/ddls/sims/ramp_job_placement_shaping/ramp_job_placement_shaping_348/checkpoints/checkpoint_000002/checkpoint-2 # USE FOR TESTING SPECIFIC CHECKPOINT (is ignored during training)
validator_rllib_config:
    explore: False
    #seed: 1799
    env_config:
        jobs_config:
            path_to_files: /scratch/datasets/ddls/jobs/pipedream_graphs/image_classification/profiles/alexnet/
            #path_to_files: /scratch/datasets/ddls/jobs/pipedream_graphs/image_classification/profiles/resnext50/
            #path_to_files: /scratch/datasets/ddls/jobs/image_classification_and_translation/small_graphs/training/
            max_files: null
            #replication_factor: 1
            replication_factor: 200
            #replication_factor: 1000
            job_interarrival_time_dist:
                _target_: ddls.distributions.uniform.Uniform
                #min_val: 1
                #max_val: 1000
                min_val: 1000
                max_val: 1000
            job_sampling_mode: remove
            shuffle_files: False
            num_training_steps: 50
            max_partitions_per_op_in_observation: 2
    num_workers: 0 # num parallel cpu workers
    num_gpus: 0 # num gpus available for RLlib

# define the rllib config as usual
rllib_config:
    #env: job_placing_all_nodes_environment
    env: ramp_job_placement_shaping_environment

    env_config:
        node_config:
            type_1:
                #num_nodes: 8
                num_nodes: 32
                workers_config:
                    #- num_workers: 4
                    - num_workers: 1
                      worker: ddls.devices.processors.gpus.A100.A100

        topology_config:
            #type: torus
            #kwargs:
                #x_dims: 4
                #y_dims: 4
            type: ramp 
            kwargs:
                num_communication_groups: 4
                num_racks_per_communication_group: 4
                num_servers_per_rack: 2
                num_channels: 1
                channel_bandwidth: 1250000000
                switch_reconfiguration_latency: 0.00000125
                worker_io_latency: 0.000000100

        jobs_config:
            path_to_files: /scratch/datasets/ddls/jobs/pipedream_graphs/image_classification/profiles/alexnet/
            #path_to_files: /scratch/datasets/ddls/jobs/pipedream_graphs/image_classification/profiles/resnext50/
            #path_to_files: /scratch/datasets/ddls/jobs/image_classification_and_translation/small_graphs/training/
            max_files: null
            #replication_factor: 1
            replication_factor: 200
            #replication_factor: 1000
            job_sampling_mode: remove
            job_interarrival_time_dist:
                _target_: ddls.distributions.uniform.Uniform
                #min_val: 1
                #max_val: 1000
                min_val: 1000
                max_val: 1000
            shuffle_files: true
            num_training_steps: 50
            max_partitions_per_op_in_observation: 2

        #reward_function: mean_job_completion_time
        reward_function: lookahead_job_completion_time
        reward_function_kwargs:
            fail_reward: job_sequential_completion_time
            fail_reward_factor: 2
            #fail_reward_factor: 1
            sign: -1
            inverse: false
            #transform_with_log: true
            transform_with_log: false
            #normaliser: job_sequential_completion_time
            normaliser: job_sequential_completion_time_times_fail_reward_factor

        op_partitioner: sip_ml_op_partitioner
        op_partitioner_kwargs:
            min_op_run_time_quantum: 0.000006 
            #max_partitions_per_op: 2

        op_placer: ramp_first_fit_op_placer

        op_scheduler: srpt_op_scheduler

        dep_placer: first_fit_dep_placer

        dep_scheduler: srpt_dep_scheduler

        pad_obs_kwargs:
            #max_nodes: 284
            max_nodes: 300

    model:
        fcnet_hiddens:
            - 8
        fcnet_activation: relu
        custom_model: my_model
        custom_model_config:
            in_features_node: 5
            in_features_edge: 2
            out_features_msg: 8
            out_features_hidden: 16
            out_features: 4
            in_features_graph: 48 # 130 34 44 11 15
            out_features_graph: 4
            num_layers: 2
            aggregator_type: mean
            action_space_type: discrete # discrete continuous

    batch_mode: complete_episodes
    #train_batch_size: 32
    #sgd_minibatch_size: 32
    train_batch_size: 4
    sgd_minibatch_size: 4
    #train_batch_size: 1
    #sgd_minibatch_size: 1

    callbacks: ddls.environments.ramp_cluster.utils.RLlibRampClusterEnvironmentCallback

    num_workers: 0 # num parallel cpu workers
    num_gpus: 1 # num gpus available for RLlib

    framework: torch
