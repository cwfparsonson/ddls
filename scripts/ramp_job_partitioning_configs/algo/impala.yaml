path_to_rllib_trainer_cls: ray.rllib.agents.impala.ImpalaTrainer

model:
    # overwrite default model config as desired
    fcnet_hiddens:
        # must == action_space.n
        - 17
    custom_model_config:
        apply_action_mask: True

algo_config:
    # SPECIFIC HPARAMS
    vtrace: True
    vtrace_clip_rho_threshold: 1.0
    vtrace_clip_pg_rho_threshold: 1.0
    vtrace_drop_last_ts: True
    num_multi_gpu_tower_stacks: 1
    minibatch_buffer_size: 1
    num_sgd_iter: 1
    replay_proportion: 0.0
    #self.replay_ratio = ((1 / self.replay_proportion)
                         #if self.replay_proportion > 0 else 0.0)
    replay_buffer_num_slots: 0
    learner_queue_size: 16
    #learner_queue_timeout: 300
    learner_queue_timeout: 600
    max_requests_in_flight_per_sampler_worker: 2
    max_requests_in_flight_per_aggregator_worker: 2
    timeout_s_sampler_manager: 0.0
    timeout_s_aggregator_manager: 0.0
    broadcast_interval: 1
    num_aggregation_workers: 0
    grad_clip: 40.0
    opt_type: adam
    lr_schedule: null
    decay: 0.99
    momentum: 0.0
    epsilon: 0.1
    vf_loss_coeff: 0.5
    entropy_coeff: 0.01
    entropy_coeff_schedule: null
    _separate_vf_optimizer: False
    _lr_vf: 0.0005
    after_train_step: null

    #train_batch_size: 50
    num_workers: 32

    ## OVERRIDE ALGORITHM CONFIG DEFAULT VALUES WITH SPECIFIC HPARAMS
    #rollout_fragment_length: 50
    #train_batch_size: 500
    #num_workers: 2
    #num_gpus: 1
    #lr: 0.0005
    #min_time_s_per_iteration: 10
